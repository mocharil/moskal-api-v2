{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "388be4d4",
   "metadata": {},
   "source": [
    "Idenya adalah\n",
    "1. jika topics belum ada,maka ambil 500 post popular pertama di 7 hari kebelakang lalu di clustering \n",
    "2. return ke UI\n",
    "3. hasil dari point pertama di masukan ke ES in background\n",
    "---\n",
    "4. jika sudah ada, maka API hanya akan send hasil yg ada di ES saja, tidak perlu bikin ulang\n",
    "---\n",
    "5. terdapat JOB yg akan melakukan point pertama berulang ulang agar data semakin kaya"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41def54f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T23:24:51.315153Z",
     "start_time": "2025-05-22T23:24:51.268938Z"
    }
   },
   "source": [
    "Contoh Output API\n",
    "\n",
    "\n",
    "{\n",
    "        \"unified_issue\": \"Banking and Financial Institution Activities\",\n",
    "        \"description\": \"Performance, strategies, and business activities of various banks and financial institutions in Indonesia.\",\n",
    "        \"list_issue\": [\n",
    "            \"Microfinance bank association members' performance\",\n",
    "            \"Morning Gymnastics at Bank Indonesia Kediri\"\n",
    "        ],\n",
    "        \"total_posts\": 291,\n",
    "        \"viral_score\": 71.81342340121046,\n",
    "        \"reach_score\": 800.3937775007216,\n",
    "        \"positive\": 149,\n",
    "        \"negative\": 7,\n",
    "        \"neutral\": 135,\n",
    "        \"share_of_voice\": 5.752124925874679\n",
    "    },"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43ff0ef",
   "metadata": {},
   "source": [
    "# untuk topics yg baru dibuat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "345d51f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T16:59:11.505915Z",
     "start_time": "2025-05-23T16:59:11.440364Z"
    },
    "code_folding": [
     15,
     38,
     43,
     67,
     92,
     128
    ]
   },
   "outputs": [],
   "source": [
    "#check apakah project sudah ada?\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from typing import List, Dict, Any, Optional\n",
    "import os, re\n",
    "import pandas as pd\n",
    "from utils.gemini import call_gemini\n",
    "from utils.list_of_mentions import get_mentions\n",
    "from utils.topics.es_operations import upsert_documents\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "ES_HOST = os.getenv('ES_HOST','http://34.101.178.71:9200')\n",
    "ES_USERNAME = os.getenv('ES_USERNAME','elastic')\n",
    "ES_PASSWORD = os.getenv('ES_PASSWORD','elasticpassword')\n",
    "# Inisialisasi client\n",
    "es = Elasticsearch(hosts=ES_HOST, http_auth = (ES_USERNAME, ES_PASSWORD))\n",
    "\n",
    "def get_data_topics(project_name):\n",
    "    query_body = {\n",
    "      \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\":{\n",
    "                \"match\":{\n",
    "                    \"project_name\":project_name\n",
    "                }\n",
    "\n",
    "            }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    data = es.search(\n",
    "        index = index_name,\n",
    "        body = query_body,\n",
    "        size = 10000\n",
    "    )\n",
    "\n",
    "    topics_overview = [i['_source'] for i in data['hits']['hits']]\n",
    "    return topics_overview\n",
    "\n",
    "def create_uuid(keyword: str) -> str:\n",
    "    \"\"\"Generate UUID for a given keyword\"\"\"\n",
    "    namespace = uuid.NAMESPACE_DNS\n",
    "    return str(uuid.uuid5(namespace, keyword))\n",
    "\n",
    "def ingest_topic(results, project_name, es = None) -> None:\n",
    "    \"\"\"Ingest topic results into Elasticsearch\"\"\"\n",
    "    if es is None:\n",
    "        es = get_elasticsearch_client()\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df['project_name'] = project_name\n",
    "    df['index'] = range(df.shape[0])\n",
    "    df['uuid'] = df.apply(lambda s: create_uuid(f\"{s['project_name']},{s['unified_issue']}\" if len(s['list_issue'])<100\\\n",
    "                                                else f\"{s['project_name']},{s['unified_issue']},{s['index']}\"), axis=1)\n",
    "\n",
    "    data_ingest = df[['unified_issue', 'description', 'list_issue', 'uuid', 'project_name']].to_dict(orient='records')\n",
    "\n",
    "    updated, created, errors = upsert_documents(\n",
    "        es,\n",
    "        data_ingest,\n",
    "        \"topics_overview\",\n",
    "        id_field=\"uuid\",\n",
    "        fields_to_update=None,\n",
    "        chunk_size=1000\n",
    "    )\n",
    "\n",
    "    print(f\"Results: {updated} documents updated, {created} documents created, {len(errors)} errors\")\n",
    "    \n",
    "def split_rows_by_list_length(df, column='list_issue', max_len=100):\n",
    "    \"\"\"\n",
    "    Membelah baris jika panjang list dalam kolom tertentu melebihi max_len.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame dengan kolom list.\n",
    "        column (str): Nama kolom yang berisi list.\n",
    "        max_len (int): Jumlah maksimum elemen per baris.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame baru dengan baris terbelah.\n",
    "    \"\"\"\n",
    "    new_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        items = row[column]\n",
    "        # Membagi list menjadi potongan dengan panjang maksimal max_len\n",
    "        chunks = [items[i:i + max_len] for i in range(0, len(items), max_len)]\n",
    "        for chunk in chunks:\n",
    "            new_row = row.copy()\n",
    "            new_row[column] = chunk\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "    return pd.DataFrame(new_rows).reset_index(drop=True)    \n",
    "\n",
    "def get_date_range(date_filter=\"last 30 days\", custom_start_date=None, custom_end_date=None):\n",
    "\n",
    "    today = datetime.now().date()\n",
    "    \n",
    "    if date_filter == \"custom\" and custom_start_date and custom_end_date:\n",
    "        return custom_start_date, custom_end_date\n",
    "    \n",
    "    if date_filter == \"yesterday\":\n",
    "        yesterday = today - timedelta(days=1)\n",
    "        return yesterday.strftime(\"%Y-%m-%d\"), yesterday.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    elif date_filter == \"this week\":\n",
    "        start_of_week = today - timedelta(days=today.weekday())\n",
    "        return start_of_week.strftime(\"%Y-%m-%d\"), today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    elif date_filter == \"last 14 days\":\n",
    "        return (today - timedelta(days=14)).strftime(\"%Y-%m-%d\"), today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    elif date_filter == \"last 7 days\":\n",
    "        return (today - timedelta(days=7)).strftime(\"%Y-%m-%d\"), today.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    elif date_filter == \"last 30 days\":\n",
    "        return (today - timedelta(days=30)).strftime(\"%Y-%m-%d\"), today.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    elif date_filter == \"last 3 months\":\n",
    "        return (today - timedelta(days=90)).strftime(\"%Y-%m-%d\"), today.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    elif date_filter == \"this year\":\n",
    "        return f\"{today.year}-01-01\", today.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    elif date_filter == \"last year\":\n",
    "        return f\"{today.year-1}-01-01\", f\"{today.year-1}-12-31\"\n",
    "    \n",
    "    else:  # \"all time\" or fallback\n",
    "        return \"2000-01-01\", today.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "def regenerate_topics(suggestion_unified_issue,df_issue):\n",
    "    #call gemini untuk clustering\n",
    "    issue_list = []\n",
    "    for idx, row in df_issue\\\n",
    "                    .sort_values(['total_post','negative_posts','total_reach_score'],\n",
    "                                ascending = [False,False,False])[:100].iterrows():\n",
    "        issue_list.append({\"id\": row['index'], \"issue\": row['issue']})\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a Social Media Analysis Expert specializing in thematic clustering of issues.\n",
    "\n",
    "    # TASK\n",
    "    Analyze and group the following list of social media issues into meaningful thematic clusters.\n",
    "\n",
    "    # IMPORTANT INSTRUCTIONS\n",
    "    1. Each issue ID must belong to EXACTLY ONE group (mutually exclusive).\n",
    "    2. Avoid any overlap of issues between groups.\n",
    "    3. Focus on identifying the main topic or theme of each issue.\n",
    "    4. Create a unified_issue name that is **clear, specific, and truly represents the essence** of the grouped issues.\n",
    "    5. Avoid using overly generic group names like \"General Issues\" or \"Various Topics.\"\n",
    "    6. Provide an informative and comprehensive description for each unified_issue that:\n",
    "       - Accurately summarizes its main theme,\n",
    "       - Highlights prevalent sentiment(s) (e.g., positive, negative, neutral),\n",
    "       - Mentions any notable patterns, concerns, or emotional tones observed,\n",
    "       - Includes relevant contextual details or recurring keywords if applicable.\n",
    "    7. If an issue is not related to the topic of \"{project_name}\", group it under the name **\"Other\"** and provide a description that clearly reflects the non-relevance to \"{project_name}.\"\n",
    "    8. Use the following suggestion list of possible unified_issue names and descriptions as references. If any suggestion fits well for a group of issues, feel free to use that unified_issue name and description exactly as provided.\n",
    "    \n",
    "    ## SUGGESTED UNIFIED_ISSUES (unified_issue and description)\n",
    "    ```\n",
    "    {suggestion_unified_issue}\n",
    "    ```\n",
    "\n",
    "    # LIST OF ISSUES\n",
    "    ```\n",
    "    {issue_list}\n",
    "    ```\n",
    "\n",
    "    # OUTPUT FORMAT\n",
    "    Return the grouped results strictly in the following JSON format:\n",
    "    ```\n",
    "    [\n",
    "    {{\n",
    "    \"unified_issue\": \"Name of Grouped Issue 1\",\n",
    "    \"description\": \"Concise description summarizing the main theme of Group 1\",\n",
    "    \"list_issue_id\": [1, 5, 10, 15]\n",
    "    }},\n",
    "    {{\n",
    "    \"unified_issue\": \"Name of Grouped Issue 2\",\n",
    "    \"description\": \"Concise description summarizing the main theme of Group 2\",\n",
    "    \"list_issue_id\": [2, 6, 11, 16]\n",
    "    }},\n",
    "    ...\n",
    "    ]\n",
    "    ```\n",
    "\n",
    "    # QUALITY PARAMETERS\n",
    "    - Group based on semantic similarity of topics and keywords.\n",
    "    - Choose a **specific** and **meaningful** name for each unified_issue that reflects the core topic clearly.\n",
    "\n",
    "    # HARD RULES:\n",
    "    - Return the output ONLY in pure JSON format, without any explanation or additional comments.\n",
    "    - The unified_issue name and description must be in English.\n",
    "    \"\"\"\n",
    "\n",
    "    centrality = call_gemini(prompt)\n",
    "    try:\n",
    "        data_center = pd.DataFrame(eval(re.findall(r'\\[.*\\]', centrality, flags=re.I|re.S)[0]))\n",
    "    except:\n",
    "        unified_issue = [i.strip('\\n ,\"') for i in re.findall(r'unified_issue[\\\"\\,\\s\\:]+(.*?)description',centrality, flags=re.I|re.S)]\n",
    "        description = [i.strip('\\n ,\"') for i in re.findall(r'description[\\\"\\,\\s\\:]+(.*?)list_issue_id',centrality, flags=re.I|re.S)]\n",
    "        list_issue_id = [eval(i.strip('\\n ,\"')) for i in re.findall(r'list_issue_id[\\\"\\,\\s\\:]+(.*?)\\}',centrality, flags=re.I|re.S)]\n",
    "\n",
    "        data = []\n",
    "        for u,d,l in zip(unified_issue, description, list_issue_id):\n",
    "            data.append({'unified_issue':u, 'description':d,'list_issue_id':l})\n",
    "        data_center = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "    df_exploded = data_center.explode('list_issue_id')\n",
    "    df_exploded = df_exploded.rename(columns={\"list_issue_id\": \"index\"})\n",
    "\n",
    "    df_merged = pd.merge(\n",
    "        df_exploded[['index', 'unified_issue', 'description']],\n",
    "        df_issue,\n",
    "        on='index',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    df_final = df_merged.groupby(['unified_issue', 'description']).agg(\n",
    "        list_issue=('issue', list),\n",
    "        total_posts=('total_post', 'sum'),\n",
    "        viral_score=('total_viral_score', 'sum'),\n",
    "        reach_score=('total_reach_score', 'sum'),\n",
    "        positive=('positive_posts', 'sum'),\n",
    "        negative=('negative_posts', 'sum'),\n",
    "        neutral=('neutral_posts', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    df_final['share_of_voice'] = (df_final['total_posts']/df_final['total_posts'].sum())*100\n",
    "    df_final = df_final.sort_values('share_of_voice', ascending=False)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47590683",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T16:59:12.234036Z",
     "start_time": "2025-05-23T16:59:12.188320Z"
    },
    "code_folding": [
     263
    ]
   },
   "outputs": [],
   "source": [
    "def get_data_issue(owner_id: Optional[str] = 1,\n",
    "    project_name: Optional[str] = None,\n",
    "    es: Optional[Elasticsearch] = None,\n",
    "    keywords: Optional[str] = [],\n",
    "    search_keyword: Optional[str] = [],\n",
    "    search_exact_phrases: bool = False,\n",
    "    case_sensitive: bool = False,\n",
    "    sentiment: Optional[str] = ['positive','negative','neutral'],\n",
    "    start_date: Optional[str] = None,\n",
    "    end_date: Optional[str] = None,\n",
    "    date_filter: str = \"last 30 days\",\n",
    "    custom_start_date: Optional[str] = None,\n",
    "    custom_end_date: Optional[str] = None,\n",
    "    channels: Optional[List[str]] = None,\n",
    "    importance: str = \"all mentions\",\n",
    "    influence_score_min: Optional[float] = 0,\n",
    "    influence_score_max: Optional[float] = 1000,\n",
    "    region: Optional[str] = [],\n",
    "    language: Optional[str] = [],\n",
    "    domain: Optional[str] = [],\n",
    "    limit=1000\n",
    "              ):\n",
    "\n",
    "    list_keywords = [\n",
    "                        {\n",
    "                          \"match\": {\n",
    "                            \"post_caption\": {\n",
    "                              \"query\": i,\n",
    "                              \"operator\": \"AND\"\n",
    "                            }\n",
    "                          }\n",
    "                        } for i in keywords\n",
    "                      ]\n",
    "    list_keywords.extend([ {\n",
    "                          \"match\": {\n",
    "                            \"issue\": {\n",
    "                              \"query\": i,\n",
    "                              \"operator\": \"AND\"\n",
    "                            }\n",
    "                          }\n",
    "                        } for i in keywords\n",
    "\n",
    "    ])\n",
    "    \n",
    "\n",
    "    if not start_date or not end_date:\n",
    "        start_date, end_date = get_date_range(\n",
    "            date_filter=date_filter,\n",
    "            custom_start_date=custom_start_date,\n",
    "            custom_end_date=custom_end_date\n",
    "        )\n",
    "    \n",
    "    \n",
    "    query = {\n",
    "      \"size\": 0,\n",
    "      \"query\": {\n",
    "        \"bool\": {\n",
    "          \"must\": [\n",
    "            {\n",
    "              \"range\": {\n",
    "                \"post_created_at\": {\n",
    "                    \"gte\": start_date,\n",
    "                    \"lte\": end_date\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"bool\": {\n",
    "                \"must\": [\n",
    "                  {\n",
    "                    \"bool\": {\n",
    "                      \"should\": list_keywords,\n",
    "\n",
    "\n",
    "\n",
    "                      \"minimum_should_match\": 1\n",
    "                    }\n",
    "                  },\n",
    "                  {\n",
    "                    \"bool\": {\n",
    "                      \"should\": [\n",
    "                        {\n",
    "                          \"match\": {\n",
    "                            \"post_caption\": {\n",
    "                              \"query\": f\"{i}\",\n",
    "                              \"operator\": \"AND\"\n",
    "                            }\n",
    "                          }\n",
    "                        } for i in search_keyword\n",
    "                      ],\n",
    "                      \"minimum_should_match\": 1\n",
    "                    }\n",
    "                  }\n",
    "                ]\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "                \n",
    "            \"bool\":{\n",
    "                \"must_not\":{\n",
    "                    \"match\":{\n",
    "                        \"issue\":\"Not Specified\"\n",
    "                        \n",
    "                    }\n",
    "                    \n",
    "                    \n",
    "                }\n",
    "                \n",
    "            }\n",
    "                \n",
    "                \n",
    "            }\n",
    "          ],\n",
    "          \"filter\": [\n",
    "            {\n",
    "              \"terms\": {\n",
    "                \"sentiment\": sentiment\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"range\": {\n",
    "                \"influence_score\": {\n",
    "                  \"gte\": influence_score_min,\n",
    "                  \"lte\": influence_score_max\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"bool\": {\n",
    "                \"should\": [\n",
    "                  {\n",
    "                    \"wildcard\": {\n",
    "                      \"region\": f\"*{i}*\"\n",
    "                    }\n",
    "                  } for i in region\n",
    "                ],\n",
    "                \"minimum_should_match\": 1\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"bool\": {\n",
    "                \"should\": [\n",
    "                  {\n",
    "                    \"wildcard\": {\n",
    "                      \"language\": f\"*{i}*\"\n",
    "                    }\n",
    "                  } for i in language\n",
    "                ],\n",
    "                \"minimum_should_match\": 1\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"bool\": {\n",
    "                \"should\": [\n",
    "                  {\n",
    "                    \"wildcard\": {\n",
    "                      \"link_post\": f\"*{i}*\"\n",
    "                    }\n",
    "                  }\n",
    "                    for i in domain\n",
    "                ],\n",
    "                \"minimum_should_match\": 1\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"bool\": {\n",
    "                \"must\": [\n",
    "                  {\n",
    "                    \"exists\": {\n",
    "                      \"field\": \"viral_score\"\n",
    "                    }\n",
    "                  },\n",
    "                  {\n",
    "                    \"exists\": {\n",
    "                      \"field\": \"sentiment\"\n",
    "                    }\n",
    "                  }\n",
    "                ]\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"from\": 0,\n",
    "      \"aggs\": {\n",
    "        \"by_issue\": {\n",
    "          \"terms\": {\n",
    "            \"field\": \"issue.keyword\",\n",
    "            \"size\": limit,\n",
    "            \"order\": {\n",
    "              \"_count\": \"desc\"\n",
    "            }\n",
    "          },\n",
    "          \"aggs\": {\n",
    "            \"total_viral_score\": {\n",
    "              \"sum\": { \"field\": \"viral_score\" }\n",
    "            },\n",
    "            \"total_reach_score\": {\n",
    "              \"sum\": { \"field\": \"reach_score\" }\n",
    "            },\n",
    "            \"total_post\": {\n",
    "              \"value_count\": { \"field\": \"issue.keyword\" }\n",
    "            },\n",
    "            \"positive_posts\": {\n",
    "              \"filter\": { \"term\": { \"sentiment\": \"positive\" } }\n",
    "            },\n",
    "            \"negative_posts\": {\n",
    "              \"filter\": { \"term\": { \"sentiment\": \"negative\" } }\n",
    "            },\n",
    "            \"neutral_posts\": {\n",
    "              \"filter\": { \"term\": { \"sentiment\": \"neutral\" } }\n",
    "            },\n",
    "            \"sample_posts\": {\n",
    "              \"top_hits\": {\n",
    "                \"size\": 2,\n",
    "                \"_source\": {\n",
    "                  \"includes\": [\n",
    "                    \"post_caption\",\n",
    "                      \"link_post\"\n",
    "                  ]\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "\n",
    "    if not channels:\n",
    "        channels = ['tiktok','instagram','news','reddit','facebook','twitter','linkedin','youtube']\n",
    "    \n",
    "    index = ','.join([i+'_data' for i in channels])\n",
    "    hasil = es.search(index = index,\n",
    "             body = query)\n",
    "    \n",
    "    buckets = hasil['aggregations']['by_issue']['buckets']\n",
    "    \n",
    "    data = []\n",
    "    for bucket in buckets:\n",
    "        sample_posts_list = []\n",
    "        for hit in bucket['sample_posts']['hits']['hits']:\n",
    "            post = hit['_source']\n",
    "            sample_posts_list.append({\n",
    "                \"post_caption\": post.get(\"post_caption\", \"\"),\n",
    "                \"link_post\": post.get(\"link_post\", \"\")\n",
    "            })\n",
    "\n",
    "        data.append({\n",
    "            \"issue\": bucket['key'],\n",
    "            \"total_viral_score\": bucket['total_viral_score']['value'],\n",
    "            \"total_reach_score\": bucket['total_reach_score']['value'],\n",
    "            \"total_post\": bucket['total_post']['value'],\n",
    "            \"positive_posts\": bucket['positive_posts']['doc_count'],\n",
    "            \"negative_posts\": bucket['negative_posts']['doc_count'],\n",
    "            \"neutral_posts\": bucket['neutral_posts']['doc_count'],\n",
    "            \"sample_posts\": sample_posts_list\n",
    "        })\n",
    "\n",
    "    # Buat DataFrame\n",
    "    df_issue = pd.DataFrame(data).reset_index()\n",
    "    return df_issue    \n",
    "\n",
    "def new_topics(owner_id: Optional[str] = 1,\n",
    "    project_name: Optional[str] = None,\n",
    "    es: Optional[Elasticsearch] = None,\n",
    "    keywords: Optional[str] = [],\n",
    "    search_keyword: Optional[str] = [],\n",
    "    search_exact_phrases: bool = False,\n",
    "    case_sensitive: bool = False,\n",
    "    sentiment: Optional[str] = ['positive','negative','neutral'],\n",
    "    start_date: Optional[str] = None,\n",
    "    end_date: Optional[str] = None,\n",
    "    date_filter: str = \"last 30 days\",\n",
    "    custom_start_date: Optional[str] = None,\n",
    "    custom_end_date: Optional[str] = None,\n",
    "    channels: Optional[List[str]] = None,\n",
    "    importance: str = \"all mentions\",\n",
    "    influence_score_min: Optional[float] = 0,\n",
    "    influence_score_max: Optional[float] = 1000,\n",
    "    region: Optional[str] = [],\n",
    "    language: Optional[str] = [],\n",
    "    domain: Optional[str] = []\n",
    "              ):\n",
    "\n",
    "    # Buat DataFrame\n",
    "    df_issue = get_data_issue(\n",
    "        owner_id = owner_id,\n",
    "        es = es,\n",
    "        project_name = project_name,\n",
    "        keywords=keywords,\n",
    "        search_keyword=search_keyword,\n",
    "        search_exact_phrases=search_exact_phrases,\n",
    "        case_sensitive=case_sensitive,\n",
    "        sentiment=sentiment,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        date_filter=date_filter,\n",
    "        custom_start_date=custom_start_date,\n",
    "        custom_end_date=custom_end_date,\n",
    "        channels=channels,\n",
    "        importance=importance,\n",
    "        influence_score_min=influence_score_min,\n",
    "        influence_score_max=influence_score_max,\n",
    "        region=region,\n",
    "        language=language,\n",
    "        domain=domain\n",
    "    \n",
    "    )\n",
    "    \n",
    "    #call gemini untuk clustering\n",
    "    issue_list = []\n",
    "    for idx, row in df_issue\\\n",
    "                    .sort_values(['total_post','negative_posts','total_reach_score'],\n",
    "                                ascending = [False,False,False])[:50].iterrows():\n",
    "        issue_list.append({\"id\": row['index'], \"issue\": row['issue']})\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a Social Media Analysis Expert specializing in thematic clustering of issues.\n",
    "\n",
    "    # TASK\n",
    "    Analyze and group the following list of social media issues into meaningful thematic clusters.\n",
    "\n",
    "    # IMPORTANT INSTRUCTIONS\n",
    "    1. Each issue ID must belong to EXACTLY ONE group (mutually exclusive).\n",
    "    2. Avoid any overlap of issues between groups.\n",
    "    3. Focus on identifying the main topic or theme of each issue.\n",
    "    4. Create a unified_issue name that is **clear, specific, and truly represents the essence** of the grouped issues.\n",
    "    5. Avoid using overly generic group names like \"General Issues\" or \"Various Topics.\"\n",
    "    6. Provide an informative and comprehensive description for each unified_issue that:\n",
    "       - Accurately summarizes its main theme,\n",
    "       - Highlights prevalent sentiment(s) (e.g., positive, negative, neutral),\n",
    "       - Mentions any notable patterns, concerns, or emotional tones observed,\n",
    "       - Includes relevant contextual details or recurring keywords if applicable.\n",
    "\n",
    "    # LIST OF ISSUES\n",
    "    ```\n",
    "    {issue_list}\n",
    "    ```\n",
    "\n",
    "    # OUTPUT FORMAT\n",
    "    Return the grouped results strictly in the following JSON format:\n",
    "    ```\n",
    "    [\n",
    "    {{\n",
    "    \"unified_issue\": \"Name of Grouped Issue 1\",\n",
    "    \"description\": \"Concise description summarizing the main theme of Group 1\",\n",
    "    \"list_issue_id\": [1, 5, 10, 15]\n",
    "    }},\n",
    "    {{\n",
    "    \"unified_issue\": \"Name of Grouped Issue 2\",\n",
    "    \"description\": \"Concise description summarizing the main theme of Group 2\",\n",
    "    \"list_issue_id\": [2, 6, 11, 16]\n",
    "    }},\n",
    "    ...\n",
    "    ]\n",
    "    ```\n",
    "\n",
    "    # QUALITY PARAMETERS\n",
    "    - Group based on semantic similarity of topics and keywords.\n",
    "    - Choose a **specific** and **meaningful** name for each unified_issue that reflects the core topic clearly.\n",
    "\n",
    "    # HARD RULES:\n",
    "    - Return the output ONLY in pure JSON format, without any explanation or additional comments.\n",
    "    - The unified_issue name and description must be in English.\n",
    "    \"\"\"\n",
    "\n",
    "    centrality = call_gemini(prompt)\n",
    "    try:\n",
    "        data_center = pd.DataFrame(eval(re.findall(r'\\[.*\\]', centrality, flags=re.I|re.S)[0]))\n",
    "    except:\n",
    "        unified_issue = [i.strip('\\n ,\"') for i in re.findall(r'unified_issue[\\\"\\,\\s\\:]+(.*?)description',centrality, flags=re.I|re.S)]\n",
    "        description = [i.strip('\\n ,\"') for i in re.findall(r'description[\\\"\\,\\s\\:]+(.*?)list_issue_id',centrality, flags=re.I|re.S)]\n",
    "        list_issue_id = [eval(i.strip('\\n ,\"')) for i in re.findall(r'list_issue_id[\\\"\\,\\s\\:]+(.*?)\\}',centrality, flags=re.I|re.S)]\n",
    "\n",
    "        data = []\n",
    "        for u,d,l in zip(unified_issue, description, list_issue_id):\n",
    "            data.append({'unified_issue':u, 'description':d,'list_issue_id':l})\n",
    "        data_center = pd.DataFrame(data)\n",
    "\n",
    "        \n",
    "    df_exploded = data_center.explode('list_issue_id')\n",
    "    df_exploded = df_exploded.rename(columns={\"list_issue_id\": \"index\"})\n",
    "\n",
    "    df_merged = pd.merge(\n",
    "        df_exploded[['index', 'unified_issue', 'description']],\n",
    "        df_issue,\n",
    "        on='index',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    df_final = df_merged.groupby(['unified_issue', 'description']).agg(\n",
    "        list_issue=('issue', list),\n",
    "        total_posts=('total_post', 'sum'),\n",
    "        viral_score=('total_viral_score', 'sum'),\n",
    "        reach_score=('total_reach_score', 'sum'),\n",
    "        positive=('positive_posts', 'sum'),\n",
    "        negative=('negative_posts', 'sum'),\n",
    "        neutral=('neutral_posts', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    df_final['share_of_voice'] = (df_final['total_posts']/df_final['total_posts'].sum())*100\n",
    "    df_final = df_final.sort_values('share_of_voice', ascending=False)\n",
    "\n",
    "    results = df_final.to_dict(orient = 'records')\n",
    "    \n",
    "    #--------------- sisa df_final di background ----------------\n",
    "    print('DIBACKGROUND')\n",
    "    ingest_topic(results, project_name, es = es)\n",
    "    \n",
    "    loop=2\n",
    "    for i in range(loop):\n",
    "        suggestion_unified_issue = df_final[['unified_issue','description']].to_dict(orient = 'records')\n",
    "        df_issue = df_issue[~df_issue['issue'].isin([j for i in df_final['list_issue'] for j in i])]\n",
    "        if df_issue.empty:\n",
    "            break\n",
    "        df_final2 = regenerate_topics(suggestion_unified_issue,df_issue)\n",
    "        df_final = pd.concat([df_final, df_final2])\n",
    "        df_final = df_final.groupby(['unified_issue']).agg(\n",
    "                description=('description', 'max'),\n",
    "                list_issue=('list_issue', lambda s: [j for i in s for j in i if not pd.isna(j)]),\n",
    "                total_posts=('total_posts', 'sum'),\n",
    "                viral_score=('viral_score', 'sum'),\n",
    "                reach_score=('reach_score', 'sum'),\n",
    "                positive=('positive', 'sum'),\n",
    "                negative=('negative', 'sum'),\n",
    "                neutral=('neutral', 'sum')).reset_index()\n",
    "        df_final['share_of_voice'] = (df_final['total_posts']/df_final['total_posts'].sum())*100\n",
    "        df_final = split_rows_by_list_length(df_final)\n",
    "\n",
    "        print(df_final.shape, df_final['unified_issue'].nunique(),len(set([j for i in df_final['list_issue'] for j in i])))\n",
    "        results = df_final.to_dict(orient = 'records')\n",
    "        ingest_topic(results, project_name,es = es)\n",
    "    # --------------------- --------------------------------------\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14cc3442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T16:59:13.449813Z",
     "start_time": "2025-05-23T16:59:13.438201Z"
    },
    "code_folding": [
     10
    ]
   },
   "outputs": [],
   "source": [
    "index_name = \"topics_overview\"\n",
    "project_name = \"danantara\"\n",
    "keywords = ['danantara',\"investasi indonesia\"]\n",
    "owner_id = 5\n",
    "search_keyword = []\n",
    "domain = []\n",
    "language = []\n",
    "region = []\n",
    "influence_score_min= 0\n",
    "influence_score_max= 1000\n",
    "sentiment = [\n",
    "    \"positive\",\n",
    "    \"negative\",\n",
    "    \"neutral\"\n",
    "  ]\n",
    "start_date = None\n",
    "end_date = None\n",
    "date_filter = 'last 7 days'\n",
    "custom_start_date=None\n",
    "custom_end_date = None\n",
    "channels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3ad7602",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T16:59:15.762854Z",
     "start_time": "2025-05-23T16:59:15.636610Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:POST http://34.101.178.71:9200/topics_overview/_search [status:200 duration:0.090s]\n"
     ]
    }
   ],
   "source": [
    "#apakah topics overview sudah ada?\n",
    "#jika sudah maka return else, olah per 500 data popular\n",
    "topics_overview = get_data_topics(project_name)\n",
    "if not topics_overview:\n",
    "    print('belum ada')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cb3dd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T16:25:24.783601Z",
     "start_time": "2025-05-23T16:24:54.732150Z"
    }
   },
   "outputs": [],
   "source": [
    "new_topics(project_name = project_name,\n",
    "           keywords = keywords,\n",
    "           es = es)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f95d4e5",
   "metadata": {},
   "source": [
    "# misalnya nyari di date lain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72d08fa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:01:36.816745Z",
     "start_time": "2025-05-23T17:01:36.806188Z"
    }
   },
   "outputs": [],
   "source": [
    "index_name = \"topics_overview\"\n",
    "project_name = \"danantara\"\n",
    "keywords = ['danantara',\"investasi indonesia\"]\n",
    "owner_id = 5\n",
    "search_keyword = []\n",
    "domain = []\n",
    "language = []\n",
    "region = []\n",
    "influence_score_min= 0\n",
    "influence_score_max= 1000\n",
    "sentiment = [\n",
    "    \"positive\",\n",
    "    \"negative\",\n",
    "    \"neutral\"\n",
    "  ]\n",
    "start_date = None\n",
    "end_date = None\n",
    "date_filter = 'last 7 days'\n",
    "custom_start_date=None\n",
    "custom_end_date = None\n",
    "channels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8225420",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:03:52.564268Z",
     "start_time": "2025-05-23T17:03:52.387774Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:POST http://34.101.178.71:9200/topics_overview/_search [status:200 duration:0.136s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sudah ada\n"
     ]
    }
   ],
   "source": [
    "#apakah topics overview sudah ada?\n",
    "#jika sudah maka return else, olah per 500 data popular\n",
    "topics_overview = get_data_topics(project_name)\n",
    "if not topics_overview:\n",
    "    print('belum ada')\n",
    "    hasil = new_topics(project_name = project_name,\n",
    "               keywords = keywords,\n",
    "               es = es)\n",
    "else:\n",
    "    print('sudah ada')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b55d18b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:04:01.615598Z",
     "start_time": "2025-05-23T17:03:59.330197Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:POST http://34.101.178.71:9200/tiktok_data,instagram_data,news_data,reddit_data,facebook_data,twitter_data,linkedin_data,youtube_data/_search [status:200 duration:2.169s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unified_issue</th>\n",
       "      <th>description</th>\n",
       "      <th>list_issue</th>\n",
       "      <th>total_posts</th>\n",
       "      <th>viral_score</th>\n",
       "      <th>reach_score</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>share_of_voice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Other</td>\n",
       "      <td>This cluster includes issues that are not dire...</td>\n",
       "      <td>[BPKH manages hajj funds effectively, BPKH man...</td>\n",
       "      <td>289</td>\n",
       "      <td>55.277300</td>\n",
       "      <td>1197.214998</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>192</td>\n",
       "      <td>42.128280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Indonesian Economic Performance and Outlook</td>\n",
       "      <td>This cluster encompasses discussions and repor...</td>\n",
       "      <td>[IHSG (Jakarta Composite Index) movement, Indo...</td>\n",
       "      <td>21</td>\n",
       "      <td>4.626327</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>3.061224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Danantara Initiatives and Support</td>\n",
       "      <td>This cluster focuses on Danantara's role, stra...</td>\n",
       "      <td>[Will Danantara become a successful force?, Da...</td>\n",
       "      <td>19</td>\n",
       "      <td>9.511562</td>\n",
       "      <td>137.681667</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2.769679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Economic and Financial Market Updates</td>\n",
       "      <td>This cluster covers various aspects of Indones...</td>\n",
       "      <td>[IHSG (Jakarta Composite Index) movement, Indo...</td>\n",
       "      <td>17</td>\n",
       "      <td>4.135826</td>\n",
       "      <td>73.700000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2.478134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Government and State Official Activities</td>\n",
       "      <td>This cluster includes activities and statement...</td>\n",
       "      <td>[Farry Francis, President's envoy, Finance Min...</td>\n",
       "      <td>15</td>\n",
       "      <td>5.252781</td>\n",
       "      <td>64.310000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2.186589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Corporate Social Responsibility and Investment...</td>\n",
       "      <td>This cluster includes news about companies eng...</td>\n",
       "      <td>[CNBC Indonesia presents investment ideas]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.092715</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>E-commerce and Logistics Challenges</td>\n",
       "      <td>This cluster focuses on challenges faced by e-...</td>\n",
       "      <td>[E-commerce players complain about high shipping]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.145773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Government Policies and Social Programs</td>\n",
       "      <td>This cluster includes discussions related to g...</td>\n",
       "      <td>[Free Nutritious Meal Program Prabowo-Gibran]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636746</td>\n",
       "      <td>4.505000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Insurance Industry Pressure</td>\n",
       "      <td>This cluster highlights the considerable press...</td>\n",
       "      <td>[Considerable pressure on the insurance industry]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.145773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Finance Ministry Plans</td>\n",
       "      <td>This cluster focuses on the Finance Ministry's...</td>\n",
       "      <td>[Finance Ministry plans 2026 budget deficit]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        unified_issue  \\\n",
       "75                                              Other   \n",
       "58        Indonesian Economic Performance and Outlook   \n",
       "28                  Danantara Initiatives and Support   \n",
       "39              Economic and Financial Market Updates   \n",
       "56           Government and State Official Activities   \n",
       "..                                                ...   \n",
       "24  Corporate Social Responsibility and Investment...   \n",
       "33                E-commerce and Logistics Challenges   \n",
       "55            Government Policies and Social Programs   \n",
       "61                        Insurance Industry Pressure   \n",
       "45                             Finance Ministry Plans   \n",
       "\n",
       "                                          description  \\\n",
       "75  This cluster includes issues that are not dire...   \n",
       "58  This cluster encompasses discussions and repor...   \n",
       "28  This cluster focuses on Danantara's role, stra...   \n",
       "39  This cluster covers various aspects of Indones...   \n",
       "56  This cluster includes activities and statement...   \n",
       "..                                                ...   \n",
       "24  This cluster includes news about companies eng...   \n",
       "33  This cluster focuses on challenges faced by e-...   \n",
       "55  This cluster includes discussions related to g...   \n",
       "61  This cluster highlights the considerable press...   \n",
       "45  This cluster focuses on the Finance Ministry's...   \n",
       "\n",
       "                                           list_issue  total_posts  \\\n",
       "75  [BPKH manages hajj funds effectively, BPKH man...          289   \n",
       "58  [IHSG (Jakarta Composite Index) movement, Indo...           21   \n",
       "28  [Will Danantara become a successful force?, Da...           19   \n",
       "39  [IHSG (Jakarta Composite Index) movement, Indo...           17   \n",
       "56  [Farry Francis, President's envoy, Finance Min...           15   \n",
       "..                                                ...          ...   \n",
       "24         [CNBC Indonesia presents investment ideas]            1   \n",
       "33  [E-commerce players complain about high shipping]            1   \n",
       "55      [Free Nutritious Meal Program Prabowo-Gibran]            1   \n",
       "61  [Considerable pressure on the insurance industry]            1   \n",
       "45       [Finance Ministry plans 2026 budget deficit]            1   \n",
       "\n",
       "    viral_score  reach_score  positive  negative  neutral  share_of_voice  \n",
       "75    55.277300  1197.214998        70        27      192       42.128280  \n",
       "58     4.626327    48.000000         3         7       11        3.061224  \n",
       "28     9.511562   137.681667         3         0       16        2.769679  \n",
       "39     4.135826    73.700000         2         5       10        2.478134  \n",
       "56     5.252781    64.310000         0         0       15        2.186589  \n",
       "..          ...          ...       ...       ...      ...             ...  \n",
       "24     0.092715     7.700000         0         0        1        0.145773  \n",
       "33     0.500000     1.550000         0         1        0        0.145773  \n",
       "55     0.636746     4.505000         0         0        1        0.145773  \n",
       "61     0.400000     0.800000         0         1        0        0.145773  \n",
       "45     0.000000     1.800000         0         0        1        0.145773  \n",
       "\n",
       "[86 rows x 10 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_issue = get_data_issue(\n",
    "    es = es,\n",
    "    project_name = project_name,\n",
    "    keywords=keywords,\n",
    "    search_keyword=search_keyword,\n",
    "    sentiment=sentiment,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    date_filter=date_filter,\n",
    "    custom_start_date=custom_start_date,\n",
    "    custom_end_date=custom_end_date,\n",
    "    channels=channels,\n",
    "    influence_score_min=influence_score_min,\n",
    "    influence_score_max=influence_score_max,\n",
    "    region=region,\n",
    "    language=language,\n",
    "    domain=domain,\n",
    "    limit=500\n",
    ")\n",
    "#ini yg direturn\n",
    "data_center = pd.DataFrame(topics_overview)\n",
    "data_center\n",
    "\n",
    "df_exploded = data_center.explode('list_issue')\n",
    "df_exploded = df_exploded.rename(columns={\"list_issue\": \"issue\"})\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    df_exploded[['issue', 'unified_issue', 'description']],\n",
    "    df_issue,\n",
    "    on='issue'\n",
    ")\n",
    "\n",
    "df_final = df_merged.groupby(['unified_issue', 'description']).agg(\n",
    "    list_issue=('issue', list),\n",
    "    total_posts=('total_post', 'sum'),\n",
    "    viral_score=('total_viral_score', 'sum'),\n",
    "    reach_score=('total_reach_score', 'sum'),\n",
    "    positive=('positive_posts', 'sum'),\n",
    "    negative=('negative_posts', 'sum'),\n",
    "    neutral=('neutral_posts', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "df_final['share_of_voice'] = (df_final['total_posts']/df_final['total_posts'].sum())*100\n",
    "df_final = df_final.sort_values('share_of_voice', ascending=False)\n",
    "\n",
    "\n",
    "results = df_final.to_dict(orient = 'records')\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "364d6292",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:04:14.618392Z",
     "start_time": "2025-05-23T17:04:14.610292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "686"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['total_posts'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf303784",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:03:08.187845Z",
     "start_time": "2025-05-23T17:03:08.162251Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------in background --------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unified_issue</th>\n",
       "      <th>description</th>\n",
       "      <th>list_issue</th>\n",
       "      <th>uuid</th>\n",
       "      <th>project_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Economic Challenges and Discussions</td>\n",
       "      <td>This cluster focuses on economic challenges an...</td>\n",
       "      <td>[Kadin discusses economic challenges, Kadin In...</td>\n",
       "      <td>6ee868af-d771-5cd5-bc72-0205a0e993b1</td>\n",
       "      <td>danantara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Economic Discussions and Government Policies</td>\n",
       "      <td>This cluster includes discussions from key gov...</td>\n",
       "      <td>[Minister of Energy's statement, Minister of F...</td>\n",
       "      <td>311e05e0-5c22-52c9-8baf-a01ca0241746</td>\n",
       "      <td>danantara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Efforts to achieve food self-sufficiency</td>\n",
       "      <td>This cluster focuses on efforts to achieve foo...</td>\n",
       "      <td>[Efforts to achieve food self-sufficiency, Coo...</td>\n",
       "      <td>0ca51090-fc99-53d8-b8b9-229d6dcb72fc</td>\n",
       "      <td>danantara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Financial Institution Initiatives</td>\n",
       "      <td>This cluster focuses on initiatives by financi...</td>\n",
       "      <td>[Kiwoom Sekuritas daily research, Bank Mandiri...</td>\n",
       "      <td>5ad2018c-a298-54e2-9f68-198b63950499</td>\n",
       "      <td>danantara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>International Cooperation and Agreements</td>\n",
       "      <td>This cluster focuses on Indonesia's cooperatio...</td>\n",
       "      <td>[Indonesia invites Japan to strengthen green e...</td>\n",
       "      <td>fd74a861-d88c-5c58-86fe-92dd3626e2b4</td>\n",
       "      <td>danantara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>IHSG and Capital Market Updates</td>\n",
       "      <td>This cluster focuses on updates and prediction...</td>\n",
       "      <td>[IHSG movement prediction and recommendations,...</td>\n",
       "      <td>5963f3ff-81fa-5cc8-937a-0758715d3b80</td>\n",
       "      <td>danantara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>International Relations and Visits</td>\n",
       "      <td>This cluster focuses on international relation...</td>\n",
       "      <td>[Australian PM Anthony Albanese's visit to Ind...</td>\n",
       "      <td>4c18161b-69c8-5664-bff4-a4c790d700f9</td>\n",
       "      <td>danantara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Investment and Economic Discussions</td>\n",
       "      <td>This cluster centers on investment-related top...</td>\n",
       "      <td>[CEO of BPI Daya discusses investment, CEO of ...</td>\n",
       "      <td>5a6ee063-c5f9-5e6b-8637-e5a09b294ecc</td>\n",
       "      <td>danantara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Other</td>\n",
       "      <td>This cluster includes issues that are not dire...</td>\n",
       "      <td>[Personal opinion article, Appreciation for lo...</td>\n",
       "      <td>3cf3a3d2-34a8-597a-8eb8-54086fbb24bb</td>\n",
       "      <td>danantara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Other</td>\n",
       "      <td>This cluster includes issues that are not dire...</td>\n",
       "      <td>[DPR RI member comments on legal issues, BRI h...</td>\n",
       "      <td>2feb79fc-a2a7-5d6c-bcd5-febcb3b32032</td>\n",
       "      <td>danantara</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   unified_issue  \\\n",
       "0            Economic Challenges and Discussions   \n",
       "1   Economic Discussions and Government Policies   \n",
       "2       Efforts to achieve food self-sufficiency   \n",
       "3              Financial Institution Initiatives   \n",
       "4       International Cooperation and Agreements   \n",
       "..                                           ...   \n",
       "84               IHSG and Capital Market Updates   \n",
       "85            International Relations and Visits   \n",
       "86           Investment and Economic Discussions   \n",
       "87                                         Other   \n",
       "88                                         Other   \n",
       "\n",
       "                                          description  \\\n",
       "0   This cluster focuses on economic challenges an...   \n",
       "1   This cluster includes discussions from key gov...   \n",
       "2   This cluster focuses on efforts to achieve foo...   \n",
       "3   This cluster focuses on initiatives by financi...   \n",
       "4   This cluster focuses on Indonesia's cooperatio...   \n",
       "..                                                ...   \n",
       "84  This cluster focuses on updates and prediction...   \n",
       "85  This cluster focuses on international relation...   \n",
       "86  This cluster centers on investment-related top...   \n",
       "87  This cluster includes issues that are not dire...   \n",
       "88  This cluster includes issues that are not dire...   \n",
       "\n",
       "                                           list_issue  \\\n",
       "0   [Kadin discusses economic challenges, Kadin In...   \n",
       "1   [Minister of Energy's statement, Minister of F...   \n",
       "2   [Efforts to achieve food self-sufficiency, Coo...   \n",
       "3   [Kiwoom Sekuritas daily research, Bank Mandiri...   \n",
       "4   [Indonesia invites Japan to strengthen green e...   \n",
       "..                                                ...   \n",
       "84  [IHSG movement prediction and recommendations,...   \n",
       "85  [Australian PM Anthony Albanese's visit to Ind...   \n",
       "86  [CEO of BPI Daya discusses investment, CEO of ...   \n",
       "87  [Personal opinion article, Appreciation for lo...   \n",
       "88  [DPR RI member comments on legal issues, BRI h...   \n",
       "\n",
       "                                    uuid project_name  \n",
       "0   6ee868af-d771-5cd5-bc72-0205a0e993b1    danantara  \n",
       "1   311e05e0-5c22-52c9-8baf-a01ca0241746    danantara  \n",
       "2   0ca51090-fc99-53d8-b8b9-229d6dcb72fc    danantara  \n",
       "3   5ad2018c-a298-54e2-9f68-198b63950499    danantara  \n",
       "4   fd74a861-d88c-5c58-86fe-92dd3626e2b4    danantara  \n",
       "..                                   ...          ...  \n",
       "84  5963f3ff-81fa-5cc8-937a-0758715d3b80    danantara  \n",
       "85  4c18161b-69c8-5664-bff4-a4c790d700f9    danantara  \n",
       "86  5a6ee063-c5f9-5e6b-8637-e5a09b294ecc    danantara  \n",
       "87  3cf3a3d2-34a8-597a-8eb8-54086fbb24bb    danantara  \n",
       "88  2feb79fc-a2a7-5d6c-bcd5-febcb3b32032    danantara  \n",
       "\n",
       "[89 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('--------------in background --------------')\n",
    "data_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e299202e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:03:09.836274Z",
     "start_time": "2025-05-23T17:03:09.829447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 10) 66 234\n"
     ]
    }
   ],
   "source": [
    "print(df_final.shape, df_final['unified_issue'].nunique(),len(set([j for i in df_final['list_issue'] for j in i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "add5d52d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:03:40.802709Z",
     "start_time": "2025-05-23T17:03:16.590423Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIBACKGROUND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:POST http://34.101.178.71:9200/topics_overview/_mget?_source=false [status:200 duration:0.042s]\n",
      "INFO:utils.topics.es_operations:Found 88 existing documents out of 102\n",
      "INFO:utils.topics.es_operations:Preparing to upsert 102 documents in topics_overview\n",
      "INFO:utils.topics.es_operations:Processing chunk 1/1 (102 documents, {'update': 88, 'index': 14})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 3) 101 692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:PUT http://34.101.178.71:9200/_bulk [status:200 duration:0.295s]\n",
      "INFO:utils.topics.es_operations:Chunk processed successfully: 102 documents\n",
      "INFO:utils.topics.es_operations:Upsert complete: 88 updated, 14 created, 0 failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 88 documents updated, 14 documents created, 0 errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:POST http://34.101.178.71:9200/topics_overview/_mget?_source=false [status:200 duration:0.058s]\n",
      "INFO:utils.topics.es_operations:Found 100 existing documents out of 103\n",
      "INFO:utils.topics.es_operations:Preparing to upsert 103 documents in topics_overview\n",
      "INFO:utils.topics.es_operations:Processing chunk 1/1 (103 documents, {'update': 100, 'index': 3})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 3) 102 788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:PUT http://34.101.178.71:9200/_bulk [status:200 duration:0.245s]\n",
      "INFO:utils.topics.es_operations:Chunk processed successfully: 103 documents\n",
      "INFO:utils.topics.es_operations:Upsert complete: 100 updated, 3 created, 0 failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 100 documents updated, 3 documents created, 0 errors\n"
     ]
    }
   ],
   "source": [
    "#--------------- sisa df_final di background ----------------\n",
    "print('DIBACKGROUND')\n",
    "df_final = pd.DataFrame(topics_overview)\n",
    "\n",
    "\n",
    "loop=2\n",
    "for i in range(loop):\n",
    "    suggestion_unified_issue = df_final[['unified_issue','description']].to_dict(orient = 'records')\n",
    "    df_issue = df_issue[~df_issue['issue'].isin([j for i in df_final['list_issue'] for j in i])]\n",
    "    if df_issue.empty:\n",
    "        break\n",
    "    df_final2 = regenerate_topics(suggestion_unified_issue,df_issue)\n",
    "    df_final = pd.concat([df_final, df_final2])\n",
    "    df_final = df_final.groupby(['unified_issue']).agg(\n",
    "            description=('description', 'max'),\n",
    "            list_issue=('list_issue', lambda s: [j for i in s for j in i if not pd.isna(j)])).reset_index()\n",
    "    df_final = split_rows_by_list_length(df_final)\n",
    "\n",
    "    print(df_final.shape, df_final['unified_issue'].nunique(),len(set([j for i in df_final['list_issue'] for j in i])))\n",
    "    results = df_final.to_dict(orient = 'records')\n",
    "    ingest_topic(results, project_name,es = es)\n",
    "# --------------------- --------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36b83e4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T16:14:26.587341Z",
     "start_time": "2025-05-24T16:14:26.581694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
