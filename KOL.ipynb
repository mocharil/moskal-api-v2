{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b5b79c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbff987",
   "metadata": {
    "code_folding": [
     15,
     30,
     49,
     55
    ]
   },
   "outputs": [],
   "source": [
    "from utils.es_client import get_elasticsearch_client\n",
    "from utils.list_of_mentions import get_mentions\n",
    "import pandas as pd\n",
    "import uuid, numpy as np\n",
    "from elasticsearch import Elasticsearch\n",
    "from utils.influence_score import get_influence_score\n",
    "from dotenv import load_dotenv\n",
    "from utils.redis_client import redis_client\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Buat koneksi ke Elasticsearch\n",
    "es = get_elasticsearch_client()\n",
    "\n",
    "def create_link_user(df):\n",
    "    if df['channel'] == 'twitter':\n",
    "        return f\"\"\"https://x.com/{df['username'].strip('@ ')}\"\"\"\n",
    "    if df['channel'] == 'instagram':\n",
    "        return f\"\"\"https://www.instagram.com/{df['username'].strip('@ ')}\"\"\"\n",
    "    if df['channel'] == 'tiktok':\n",
    "        return f\"\"\"https://www.tiktok.com/@{df['username'].strip('@ ')}\"\"\"\n",
    "    if df['channel']=='linkedin':\n",
    "        return f\"\"\"https://www.linkedin.com/in/{df['username'].strip('@ ')}\"\"\"\n",
    "    if df['channel']=='reddit':\n",
    "        return f\"\"\"https://www.reddit.com/{df['username'].strip('@ ')}\"\"\"\n",
    "    \n",
    "    \n",
    "    return df['username']\n",
    "    \n",
    "def add_negative_driver_flag(df):\n",
    "\n",
    "    # Ensure all sentiment columns exist\n",
    "    for sentiment in ['positive', 'negative', 'neutral']:\n",
    "        col_name = f'sentiment_{sentiment}'\n",
    "        if col_name not in df.columns:\n",
    "            df[col_name] = 0\n",
    "    \n",
    "    # Create a new column that checks if negative sentiment is the highest\n",
    "    df['is_negative_driver'] = False\n",
    "    \n",
    "    # Compare sentiment counts and set flag if negative is highest\n",
    "    condition = ((df['sentiment_negative'] > df['sentiment_positive']) & \n",
    "                 (df['sentiment_negative'] > df['sentiment_neutral']))\n",
    "    \n",
    "    df['is_negative_driver'] = condition\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_uuid(keyword):\n",
    "    # Gunakan namespace standar (ada juga untuk URL, DNS, dll)\n",
    "    namespace = uuid.NAMESPACE_DNS\n",
    "\n",
    "    return uuid.uuid5(namespace, keyword)\n",
    "\n",
    "def rule_base_user_category(string, category):\n",
    "    if pd.isna(string):\n",
    "        return ''\n",
    "    \n",
    "    if 'news' in string.lower():\n",
    "        return 'News Account'\n",
    "\n",
    "    return category\n",
    "    \n",
    "def search_kol(   owner_id = None,\n",
    "    project_name = None,\n",
    "    es_host=None,\n",
    "    es_username=None,\n",
    "    es_password=None,\n",
    "    use_ssl=False,\n",
    "    verify_certs=False,\n",
    "    ca_certs=None,\n",
    "    keywords=None,\n",
    "    search_keyword=None,\n",
    "    search_exact_phrases=False,\n",
    "    case_sensitive=False,\n",
    "    sentiment=None,\n",
    "    start_date=None,\n",
    "    end_date=None,\n",
    "    date_filter=\"last 30 days\",\n",
    "    custom_start_date=None,\n",
    "    custom_end_date=None,\n",
    "    channels=None,\n",
    "    importance=\"all mentions\",\n",
    "    influence_score_min=None,\n",
    "    influence_score_max=None,\n",
    "    region=None,\n",
    "    language=None,\n",
    "    domain=None):\n",
    "\n",
    "    # Generate cache key based on all parameters\n",
    "    cache_key = redis_client.generate_cache_key(\n",
    "        \"kol_overview\",\n",
    "        owner_id=owner_id,\n",
    "        project_name=project_name,\n",
    "        keywords=keywords,\n",
    "        search_keyword=search_keyword,\n",
    "        search_exact_phrases=search_exact_phrases,\n",
    "        case_sensitive=case_sensitive,\n",
    "        start_date=start_date,\n",
    "        sentiment=sentiment,\n",
    "        end_date=end_date,\n",
    "        date_filter=date_filter,\n",
    "        custom_start_date=custom_start_date,\n",
    "        custom_end_date=custom_end_date,\n",
    "        channels=channels,\n",
    "        importance=importance,\n",
    "        influence_score_min=influence_score_min,\n",
    "        influence_score_max=influence_score_max,\n",
    "        region=region,\n",
    "        language=language,\n",
    "        domain=domain\n",
    "    )\n",
    "\n",
    "    # Try to get from cache first\n",
    "    cached_result = redis_client.get(cache_key)\n",
    "    if cached_result is not None:\n",
    "        print('Returning cached result')\n",
    "        return cached_result\n",
    "\n",
    "\n",
    "    print('get all data mentions')\n",
    "\n",
    "    if not sentiment:\n",
    "        sentiment = ['positive','negative','neutral']\n",
    "\n",
    "    result = get_mentions(\n",
    "            source= [\"issue\",\"user_connections\",\"user_followers\",\"user_influence_score\",\n",
    "                     'user_image_url',\"engagement_rate\",\"subscriber\",\n",
    "                 \"influence_score\",\"reach_score\", \"viral_score\",\n",
    "                 \"sentiment\", \"link_post\",\"user_category\",\"username\",'channel',\n",
    "                \"votes\",\"likes\",'comments','shares','retweets','reports','replies',\n",
    "                 'views','favorites',\"post_created_at\"],\n",
    "            page_size=10000,\n",
    "            es_host=es_host,    \n",
    "            es_username=es_username,\n",
    "            es_password=es_password,\n",
    "            use_ssl=use_ssl,\n",
    "            verify_certs=verify_certs,\n",
    "            ca_certs=ca_certs,\n",
    "            keywords=keywords,\n",
    "            search_keyword=search_keyword,\n",
    "            search_exact_phrases=search_exact_phrases,\n",
    "            case_sensitive=case_sensitive,\n",
    "            sentiment=sentiment,\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "            date_filter=date_filter,\n",
    "            custom_start_date=custom_start_date,\n",
    "            custom_end_date=custom_end_date,\n",
    "            channels=channels,\n",
    "            importance=importance,\n",
    "            influence_score_min=influence_score_min,\n",
    "            influence_score_max=influence_score_max,\n",
    "            region=region,\n",
    "            language=language,\n",
    "            domain=domain,\n",
    "            sort_type = 'popular'\n",
    "        )\n",
    "\n",
    "    if not result['data']:\n",
    "        return []\n",
    "    else:\n",
    "        kol = pd.DataFrame(result['data'])\n",
    "\n",
    "        #-----------------------\n",
    "        if 'user_category' not in kol:\n",
    "            kol['user_category']=''\n",
    "\n",
    "        kol['user_category'] = kol.apply(lambda s: 'News Account' if s['channel'] == 'news' else rule_base_user_category(s['username'], s['user_category']), axis=1)\n",
    "\n",
    "        kol['user_influence_score'] = kol.apply(lambda s: get_influence_score(s), axis=1)\n",
    "\n",
    "        #-----------------------            \n",
    "        for c in set(['user_connections','user_followers','subscriber']) - set(kol.columns):\n",
    "            kol[c] = 0                   \n",
    "\n",
    "\n",
    "        kol[['user_followers',\"subscriber\"]] = kol[['user_followers',\"subscriber\"]].fillna(0)\n",
    "        kol['user_category'] = kol['user_category'].fillna('')\n",
    "\n",
    "        kol['link_user'] = kol.apply(lambda s: create_link_user(s), axis=1)        \n",
    "\n",
    "        for i in set(['user_connections','user_followers','subscriber']) - set(kol):\n",
    "            kol[i] = 0\n",
    "\n",
    "        kol['user_followers'] = kol['user_connections'] + kol['user_followers'] + kol['subscriber']\n",
    "\n",
    "        # Your groupby with sentiment pivot\n",
    "        agg_kol = kol.groupby(['link_user']).agg({\n",
    "            'link_post': 'size',\n",
    "            'viral_score': 'sum',\n",
    "            'reach_score': 'sum',\n",
    "            'channel': 'max',\n",
    "            'username': 'max',\n",
    "            'user_image_url':'max',\n",
    "            'user_followers':'max',\n",
    "            \"engagement_rate\":'sum',\n",
    "            'issue': lambda s: list(set(s)),\n",
    "            'user_category': 'max',\n",
    "            'user_influence_score': 'mean'\n",
    "        })\n",
    "\n",
    "        # Get sentiment counts per link_user using crosstab\n",
    "        sentiment_counts = pd.crosstab(kol['link_user'], kol['sentiment'])\n",
    "\n",
    "        # Rename columns to add 'sentiment_' prefix\n",
    "        sentiment_counts = sentiment_counts.add_prefix('sentiment_')\n",
    "\n",
    "        # Join the sentiment counts with the main result\n",
    "        final_kol = agg_kol.join(sentiment_counts)\n",
    "\n",
    "        # If any sentiment category is missing, add it with zeros\n",
    "        for sentiment in ['positive', 'negative', 'neutral']:\n",
    "            col_name = f'sentiment_{sentiment}'\n",
    "            if col_name not in final_kol.columns:\n",
    "                final_kol[col_name] = 0        \n",
    "\n",
    "\n",
    "        # Apply the function to final_kol\n",
    "        final_kol = add_negative_driver_flag(final_kol).reset_index()\n",
    "\n",
    "        list_issue = [j for i in final_kol['issue'] for j in i]\n",
    "\n",
    "        print('check topic map')\n",
    "        #check issue mana yang sudah termap dan mana yg belum\n",
    "        query_body = {\n",
    "            \"_source\":[\"unified_issue\",\"list_issue\"],\n",
    "            \"query\":{\n",
    "\n",
    "                \"bool\": {\n",
    "\n",
    "                    \"must\":[\n",
    "\n",
    "                        {        \"match\": {\"project_name.keyword\":project_name}   },\n",
    "                        {        \"terms\": {\"list_issue.keyword\":list_issue}  },\n",
    "\n",
    "\n",
    "                    ]\n",
    "\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        response = es.search(\n",
    "            index=\"topic_cluster\",\n",
    "            body=query_body,\n",
    "            size = 10000\n",
    "        )\n",
    "        top_map = [i['_source'] for i in response['hits']['hits']]\n",
    "        dict_issue = {}\n",
    "        if top_map:\n",
    "            print('get map')\n",
    "            df_map = pd.DataFrame(top_map)\n",
    "            df_map = df_map.explode('list_issue').drop_duplicates('list_issue')\n",
    "            \n",
    "            for _,i in df_map.iterrows():\n",
    "                dict_issue.update({i['list_issue']:i['unified_issue']})\n",
    "\n",
    "        final_kol['unified_issue'] = final_kol['issue'].transform(lambda s: list(set([dict_issue.get(i,i) for i in s]))[:5])\n",
    "        final_kol['user_category'] = final_kol.apply(lambda s: 'News Account' if s['channel']=='news' else s['user_category'], axis=1)\n",
    "        final_kol.drop('issue', axis=1, inplace=True)\n",
    "        final_kol['most_viral'] = final_kol['user_influence_score']\n",
    "\n",
    "\n",
    "        final_kol[\"share_of_voice\"] = (final_kol[\"link_post\"]/final_kol[\"link_post\"].sum())*100\n",
    "        \n",
    "        most_negative_kol = final_kol.sort_values(['is_negative_driver','sentiment_negative','most_viral'], ascending = False)[:100]\n",
    "        most_viral_kol = final_kol.sort_values('most_viral', ascending = False)[:100]\n",
    "        \n",
    "        final_kol = pd.concat([most_negative_kol,most_viral_kol]).drop_duplicates('link_user')\n",
    "\n",
    "\n",
    "        result = final_kol.sort_values(['is_negative_driver','sentiment_negative','most_viral'], ascending = False)[:150].to_dict(orient = 'records')\n",
    "        \n",
    "        # Cache the results for 10 minutes\n",
    "        redis_client.set_with_ttl(cache_key, result, ttl_seconds=600)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04981b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    {\n",
    "        \"link_user\": \"poskota.co.id\",\n",
    "        \"link_post\": 328,\n",
    "        \"viral_score\": 25.95794271789944,\n",
    "        \"reach_score\": 295.8,\n",
    "        \"channel\": \"news\",\n",
    "        \"username\": \"poskota.co.id\",\n",
    "        \"user_image_url\": \"https://logo.clearbit.com/poskota.co.id\",\n",
    "        \"user_followers\": 0.0,\n",
    "        \"engagement_rate\": 35957.92366030789,\n",
    "        \"user_category\": \"News Account\",\n",
    "        \"user_influence_score\": 6.0,\n",
    "        \"sentiment_negative\": 127,\n",
    "        \"sentiment_neutral\": 118,\n",
    "        \"sentiment_positive\": 83,\n",
    "        \"is_negative_driver\": true,\n",
    "        \"unified_issue\": [\n",
    "            \"5 legal online loans registered in OJK\",\n",
    "            \"Bank Indonesia maintains benchmark interest rate\",\n",
    "            \"5 effective ways to overcome stress\",\n",
    "            \"Financial Literacy and Consumer Awareness\",\n",
    "            \"How to transfer Gopay balance to bank\"\n",
    "        ],\n",
    "        \"most_viral\": 6.0,\n",
    "        \"share_of_voice\": 3.2800000000000002\n",
    "    },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d754f34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T17:38:43.539036Z",
     "start_time": "2025-05-24T17:38:43.530651Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1843880290.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Aril Indra Permana\\AppData\\Local\\Temp\\ipykernel_28988\\1843880290.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    link_post -> count\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "username,\n",
    "link_post -> count\n",
    "viral_score -> sum\n",
    "reach_score -> sum\n",
    "channel -> 1 unique\n",
    "user_image_url -> 1 unique\n",
    "user_followers -> max\n",
    "engagement_rate -> sum\n",
    "user_category -> 1 unique\n",
    "user_influence_score -> sum\n",
    "sentiment -> pecah jadi 3 yaitu sentiment_negative, sentiment_positive, sentiment_neutral\n",
    "issue -> list unique issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dec4548",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T18:16:05.743336Z",
     "start_time": "2025-05-24T18:15:53.984562Z"
    },
    "code_folding": [
     89
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------connect to redis----------------\n",
      "Successfully connected to http://34.101.178.71:9200\n"
     ]
    }
   ],
   "source": [
    "from utils.es_client import get_elasticsearch_client\n",
    "from utils.es_query_builder import build_elasticsearch_query, get_indices_from_channels, get_date_range\n",
    "from utils.script_score import script_score\n",
    "import pandas as pd\n",
    "import uuid, numpy as np\n",
    "from elasticsearch import Elasticsearch\n",
    "from dotenv import load_dotenv\n",
    "from utils.redis_client import redis_client\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Buat koneksi ke Elasticsearch\n",
    "es = get_elasticsearch_client()\n",
    "\n",
    "def create_link_user(df):\n",
    "    if df['channel'] == 'twitter':\n",
    "        return f\"\"\"https://x.com/{df['username'].strip('@ ')}\"\"\"\n",
    "    if df['channel'] == 'instagram':\n",
    "        return f\"\"\"https://www.instagram.com/{df['username'].strip('@ ')}\"\"\"\n",
    "    if df['channel'] == 'tiktok':\n",
    "        return f\"\"\"https://www.tiktok.com/@{df['username'].strip('@ ')}\"\"\"\n",
    "    if df['channel']=='linkedin':\n",
    "        return f\"\"\"https://www.linkedin.com/in/{df['username'].strip('@ ')}\"\"\"\n",
    "    if df['channel']=='reddit':\n",
    "        return f\"\"\"https://www.reddit.com/{df['username'].strip('@ ')}\"\"\"\n",
    "    \n",
    "    return df['username']\n",
    "    \n",
    "def add_negative_driver_flag(df):\n",
    "    # Ensure all sentiment columns exist\n",
    "    for sentiment in ['positive', 'negative', 'neutral']:\n",
    "        col_name = f'sentiment_{sentiment}'\n",
    "        if col_name not in df.columns:\n",
    "            df[col_name] = 0\n",
    "    \n",
    "    # Create a new column that checks if negative sentiment is the highest\n",
    "    df['is_negative_driver'] = False\n",
    "    \n",
    "    # Compare sentiment counts and set flag if negative is highest\n",
    "    condition = ((df['sentiment_negative'] > df['sentiment_positive']) & \n",
    "                 (df['sentiment_negative'] > df['sentiment_neutral']))\n",
    "    \n",
    "    df['is_negative_driver'] = condition\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_uuid(keyword):\n",
    "    # Gunakan namespace standar (ada juga untuk URL, DNS, dll)\n",
    "    namespace = uuid.NAMESPACE_DNS\n",
    "    return uuid.uuid5(namespace, keyword)\n",
    "\n",
    "def rule_base_user_category(string, category):\n",
    "    if pd.isna(string):\n",
    "        return ''\n",
    "    \n",
    "    if 'news' in string.lower():\n",
    "        return 'News Account'\n",
    "\n",
    "    return category\n",
    "    \n",
    "def search_kol(\n",
    "    owner_id = None,\n",
    "    project_name = None,\n",
    "    es_host=None,\n",
    "    es_username=None,\n",
    "    es_password=None,\n",
    "    use_ssl=False,\n",
    "    verify_certs=False,\n",
    "    ca_certs=None,\n",
    "    keywords=None,\n",
    "    search_keyword=None,\n",
    "    search_exact_phrases=False,\n",
    "    case_sensitive=False,\n",
    "    sentiment=None,\n",
    "    start_date=None,\n",
    "    end_date=None,\n",
    "    date_filter=\"last 30 days\",\n",
    "    custom_start_date=None,\n",
    "    custom_end_date=None,\n",
    "    channels=None,\n",
    "    importance=\"all mentions\",\n",
    "    influence_score_min=None,\n",
    "    influence_score_max=None,\n",
    "    region=None,\n",
    "    language=None,\n",
    "    domain=None):\n",
    "\n",
    "    # Generate cache key based on all parameters\n",
    "    cache_key = redis_client.generate_cache_key(\n",
    "        \"kol_overview\",\n",
    "        owner_id=owner_id,\n",
    "        project_name=project_name,\n",
    "        keywords=keywords,\n",
    "        search_keyword=search_keyword,\n",
    "        search_exact_phrases=search_exact_phrases,\n",
    "        case_sensitive=case_sensitive,\n",
    "        start_date=start_date,\n",
    "        sentiment=sentiment,\n",
    "        end_date=end_date,\n",
    "        date_filter=date_filter,\n",
    "        custom_start_date=custom_start_date,\n",
    "        custom_end_date=custom_end_date,\n",
    "        channels=channels,\n",
    "        importance=importance,\n",
    "        influence_score_min=influence_score_min,\n",
    "        influence_score_max=influence_score_max,\n",
    "        region=region,\n",
    "        language=language,\n",
    "        domain=domain\n",
    "    )\n",
    "\n",
    "    # Try to get from cache first\n",
    "    cached_result = redis_client.get(cache_key)\n",
    "    if cached_result is not None:\n",
    "        print('Returning cached result')\n",
    "        return cached_result\n",
    "\n",
    "    print('get all data mentions using aggregation')\n",
    "\n",
    "    if not sentiment:\n",
    "        sentiment = ['positive','negative','neutral']\n",
    "\n",
    "    # Buat koneksi Elasticsearch\n",
    "    es_conn = get_elasticsearch_client(\n",
    "        es_host=es_host,\n",
    "        es_username=es_username,\n",
    "        es_password=es_password,\n",
    "        use_ssl=use_ssl,\n",
    "        verify_certs=verify_certs,\n",
    "        ca_certs=ca_certs\n",
    "    )\n",
    "    \n",
    "    if not es_conn:\n",
    "        return []\n",
    "    \n",
    "    # Dapatkan indeks dari channel\n",
    "    indices = get_indices_from_channels(channels)\n",
    "    \n",
    "    if not indices:\n",
    "        print(\"Error: Tidak ada indeks yang valid\")\n",
    "        return []\n",
    "    \n",
    "    # Dapatkan rentang tanggal jika tidak disediakan\n",
    "    if not start_date or not end_date:\n",
    "        start_date, end_date = get_date_range(\n",
    "            date_filter=date_filter,\n",
    "            custom_start_date=custom_start_date,\n",
    "            custom_end_date=custom_end_date\n",
    "        )\n",
    "\n",
    "    # Build base query menggunakan es_query_builder\n",
    "    base_query = build_elasticsearch_query(\n",
    "        keywords=keywords,\n",
    "        search_keyword=search_keyword,\n",
    "        search_exact_phrases=search_exact_phrases,\n",
    "        case_sensitive=case_sensitive,\n",
    "        sentiment=sentiment,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        importance=importance,\n",
    "        influence_score_min=influence_score_min,\n",
    "        influence_score_max=influence_score_max,\n",
    "        region=region,\n",
    "        language=language,\n",
    "        domain=domain,\n",
    "        size=0  # Untuk aggregation saja\n",
    "    )\n",
    "\n",
    "    # Tambahkan aggregation untuk KOL analysis\n",
    "    aggregation_query = {\n",
    "        \"by_username_channel\": {\n",
    "            \"terms\": {\n",
    "                \"script\": {\n",
    "                    \"source\": \"\"\"\n",
    "                        String username = doc.containsKey('username') && !doc['username'].empty ? doc['username'].value : 'unknown';\n",
    "                        String channel = doc.containsKey('channel') && !doc['channel'].empty ? doc['channel'].value : 'unknown';\n",
    "                        return username + '|' + channel;\n",
    "                    \"\"\"\n",
    "                },\n",
    "                \"size\": 1000,  # Increase size to get more KOLs\n",
    "                \"order\": [\n",
    "                    {\n",
    "                        \"user_influence_score_avg\": \"desc\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"followers_count\": \"desc\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"total_posts\": \"desc\"\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            \"aggs\": {\n",
    "                \"username\": {\n",
    "                    \"terms\": {\n",
    "                        \"field\": \"username\",\n",
    "                        \"size\": 1\n",
    "                    }\n",
    "                },\n",
    "                \"channel\": {\n",
    "                    \"terms\": {\n",
    "                        \"field\": \"channel\",\n",
    "                        \"size\": 1\n",
    "                    }\n",
    "                },\n",
    "                \"followers_count\": {\n",
    "                    \"max\": {\n",
    "                        \"script\": {\n",
    "                            \"source\": \"\"\"\n",
    "                                // Logic untuk followers dengan fallback - menggunakan max untuk mendapatkan nilai tertinggi per user\n",
    "                                if (doc.containsKey('user_followers') && !doc['user_followers'].empty) {\n",
    "                                    return doc['user_followers'].value;\n",
    "                                } else if (doc.containsKey('user_connections') && !doc['user_connections'].empty) {\n",
    "                                    return doc['user_connections'].value;\n",
    "                                } else if (doc.containsKey('subscriber') && !doc['subscriber'].empty) {\n",
    "                                    return doc['subscriber'].value;\n",
    "                                } else {\n",
    "                                    return 0;\n",
    "                                }\n",
    "                            \"\"\"\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"total_posts\": {\n",
    "                    \"value_count\": {\n",
    "                        \"field\": \"username\"\n",
    "                    }\n",
    "                },\n",
    "                \"viral_score_sum\": {\n",
    "                    \"sum\": {\n",
    "                        \"field\": \"viral_score\"\n",
    "                    }\n",
    "                },\n",
    "                \"reach_score_sum\": {\n",
    "                    \"sum\": {\n",
    "                        \"field\": \"reach_score\"\n",
    "                    }\n",
    "                },\n",
    "                \"unique_user_image_url\": {\n",
    "                    \"terms\": {\n",
    "                        \"field\": \"user_image_url\",\n",
    "                        \"size\": 1\n",
    "                    }\n",
    "                },\n",
    "                \"engagement_rate_sum\": {\n",
    "                    \"sum\": {\n",
    "                        \"field\": \"engagement_rate\"\n",
    "                    }\n",
    "                },\n",
    "                \"unique_user_category\": {\n",
    "                    \"terms\": {\n",
    "                        \"field\": \"user_category.keyword\",\n",
    "                        \"size\": 1\n",
    "                    }\n",
    "                },\n",
    "                \"user_influence_score_avg\": {\n",
    "                    \"avg\": {\n",
    "                        \"script\": script_score\n",
    "                    }\n",
    "                },\n",
    "                \"sentiment_positive\": {\n",
    "                    \"filter\": {\n",
    "                        \"term\": {\n",
    "                            \"sentiment\": \"positive\"\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"sentiment_negative\": {\n",
    "                    \"filter\": {\n",
    "                        \"term\": {\n",
    "                            \"sentiment\": \"negative\"\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"sentiment_neutral\": {\n",
    "                    \"filter\": {\n",
    "                        \"term\": {\n",
    "                            \"sentiment\": \"neutral\"\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"unique_issues\": {\n",
    "                    \"terms\": {\n",
    "                        \"field\": \"issue.keyword\",\n",
    "                        \"size\": 10\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Tambahkan aggregation ke base query\n",
    "    base_query[\"aggs\"] = aggregation_query\n",
    "\n",
    "    try:\n",
    "        import json\n",
    "        print(json.dumps(base_query, indent=2))\n",
    "        \n",
    "        # Execute aggregation query\n",
    "        response = es_conn.search(\n",
    "            index=\",\".join(indices),\n",
    "            body=base_query\n",
    "        )\n",
    "        \n",
    "        # Process aggregation results\n",
    "        buckets = response[\"aggregations\"][\"by_username_channel\"][\"buckets\"]\n",
    "        \n",
    "        if not buckets:\n",
    "            return []\n",
    "        \n",
    "        # Convert aggregation results to DataFrame format\n",
    "        kol_data = []\n",
    "        for bucket in buckets:\n",
    "            username_channel = bucket[\"key\"]\n",
    "            username = bucket[\"username\"][\"buckets\"][0][\"key\"] if bucket[\"username\"][\"buckets\"] else \"unknown\"\n",
    "            channel = bucket[\"channel\"][\"buckets\"][0][\"key\"] if bucket[\"channel\"][\"buckets\"] else \"unknown\"\n",
    "            \n",
    "            # Extract issues list\n",
    "            issues_list = [issue_bucket[\"key\"] for issue_bucket in bucket[\"unique_issues\"][\"buckets\"]]\n",
    "            \n",
    "            # Get user_category\n",
    "            user_category = \"\"\n",
    "            if bucket[\"unique_user_category\"][\"buckets\"]:\n",
    "                user_category = bucket[\"unique_user_category\"][\"buckets\"][0][\"key\"]\n",
    "            \n",
    "            # Get user_image_url\n",
    "            user_image_url = \"\"\n",
    "            if bucket[\"unique_user_image_url\"][\"buckets\"]:\n",
    "                user_image_url = bucket[\"unique_user_image_url\"][\"buckets\"][0][\"key\"]\n",
    "            \n",
    "            kol_record = {\n",
    "                'username': username,\n",
    "                'channel': channel,\n",
    "                'link_post': bucket[\"total_posts\"][\"value\"],\n",
    "                'viral_score': bucket[\"viral_score_sum\"][\"value\"],\n",
    "                'reach_score': bucket[\"reach_score_sum\"][\"value\"],\n",
    "                'user_image_url': user_image_url,\n",
    "                'user_followers': bucket[\"followers_count\"][\"value\"],\n",
    "                'engagement_rate': bucket[\"engagement_rate_sum\"][\"value\"],\n",
    "                'issue': issues_list,\n",
    "                'user_category': user_category,\n",
    "                'user_influence_score': bucket[\"user_influence_score_avg\"][\"value\"],\n",
    "                'sentiment_positive': bucket[\"sentiment_positive\"][\"doc_count\"],\n",
    "                'sentiment_negative': bucket[\"sentiment_negative\"][\"doc_count\"],\n",
    "                'sentiment_neutral': bucket[\"sentiment_neutral\"][\"doc_count\"]\n",
    "            }\n",
    "            kol_data.append(kol_record)\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        final_kol = pd.DataFrame(kol_data)\n",
    "        \n",
    "        if final_kol.empty:\n",
    "            return []\n",
    "\n",
    "        # Apply business logic transformations\n",
    "        final_kol['user_category'] = final_kol.apply(lambda s: 'News Account' if s['channel'] == 'news' else rule_base_user_category(s['username'], s['user_category']), axis=1)\n",
    "        final_kol['link_user'] = final_kol.apply(lambda s: create_link_user(s), axis=1)\n",
    "        \n",
    "        # Apply negative driver flag\n",
    "        final_kol = add_negative_driver_flag(final_kol)\n",
    "        \n",
    "        # Get all unique issues for topic mapping\n",
    "        list_issue = [j for i in final_kol['issue'] for j in i]\n",
    "\n",
    "        print('check topic map')\n",
    "        # Check issue mapping (same logic as before)\n",
    "        query_body = {\n",
    "            \"_source\": [\"unified_issue\", \"list_issue\"],\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must\": [\n",
    "                        {\"match\": {\"project_name.keyword\": project_name}},\n",
    "                        {\"terms\": {\"list_issue.keyword\": list_issue}},\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        response = es.search(\n",
    "            index=\"topic_cluster\",\n",
    "            body=query_body,\n",
    "            size=10000\n",
    "        )\n",
    "        \n",
    "        top_map = [i['_source'] for i in response['hits']['hits']]\n",
    "        dict_issue = {}\n",
    "        if top_map:\n",
    "            print('get map')\n",
    "            df_map = pd.DataFrame(top_map)\n",
    "            df_map = df_map.explode('list_issue').drop_duplicates('list_issue')\n",
    "            \n",
    "            for _, i in df_map.iterrows():\n",
    "                dict_issue.update({i['list_issue']: i['unified_issue']})\n",
    "\n",
    "        # Apply unified issue mapping\n",
    "        final_kol['unified_issue'] = final_kol['issue'].transform(lambda s: list(set([dict_issue.get(i, i) for i in s]))[:5])\n",
    "        final_kol['user_category'] = final_kol.apply(lambda s: 'News Account' if s['channel'] == 'news' else s['user_category'], axis=1)\n",
    "        final_kol.drop('issue', axis=1, inplace=True)\n",
    "        final_kol['most_viral'] = final_kol['user_influence_score']\n",
    "\n",
    "        # Calculate share of voice\n",
    "        final_kol[\"share_of_voice\"] = (final_kol[\"link_post\"] / final_kol[\"link_post\"].sum()) * 100\n",
    "        \n",
    "        # Get top KOLs\n",
    "        most_negative_kol = final_kol.sort_values(['is_negative_driver', 'sentiment_negative', 'most_viral'], ascending=False)[:100]\n",
    "        most_viral_kol = final_kol.sort_values('most_viral', ascending=False)[:100]\n",
    "        \n",
    "        final_kol = pd.concat([most_negative_kol, most_viral_kol]).drop_duplicates('link_user')\n",
    "\n",
    "        result = final_kol.sort_values(['is_negative_driver', 'sentiment_negative', 'most_viral'], ascending=False)[:150].to_dict(orient='records')\n",
    "        \n",
    "        # Cache the results for 10 minutes\n",
    "        redis_client.set_with_ttl(cache_key, result, ttl_seconds=600)\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error executing aggregation query: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f9d115d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T18:24:29.206616Z",
     "start_time": "2025-05-24T18:24:28.631754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get all data mentions using aggregation\n",
      "Successfully connected to http://34.101.178.71:9200\n",
      "{\n",
      "  \"size\": 0,\n",
      "  \"query\": {\n",
      "    \"bool\": {\n",
      "      \"must\": [\n",
      "        {\n",
      "          \"range\": {\n",
      "            \"post_created_at\": {\n",
      "              \"gte\": \"2000-01-01\",\n",
      "              \"lte\": \"2025-05-25\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"bool\": {\n",
      "            \"must\": [\n",
      "              {\n",
      "                \"bool\": {\n",
      "                  \"should\": [\n",
      "                    {\n",
      "                      \"match\": {\n",
      "                        \"post_caption\": {\n",
      "                          \"query\": \"prabowo\",\n",
      "                          \"operator\": \"AND\"\n",
      "                        }\n",
      "                      }\n",
      "                    },\n",
      "                    {\n",
      "                      \"match\": {\n",
      "                        \"issue\": {\n",
      "                          \"query\": \"prabowo\",\n",
      "                          \"operator\": \"AND\"\n",
      "                        }\n",
      "                      }\n",
      "                    },\n",
      "                    {\n",
      "                      \"match\": {\n",
      "                        \"post_caption\": {\n",
      "                          \"query\": \"gibran\",\n",
      "                          \"operator\": \"AND\"\n",
      "                        }\n",
      "                      }\n",
      "                    },\n",
      "                    {\n",
      "                      \"match\": {\n",
      "                        \"issue\": {\n",
      "                          \"query\": \"gibran\",\n",
      "                          \"operator\": \"AND\"\n",
      "                        }\n",
      "                      }\n",
      "                    }\n",
      "                  ],\n",
      "                  \"minimum_should_match\": 1\n",
      "                }\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"filter\": [\n",
      "        {\n",
      "          \"terms\": {\n",
      "            \"sentiment\": [\n",
      "              \"positive\",\n",
      "              \"negative\",\n",
      "              \"neutral\"\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"aggs\": {\n",
      "    \"by_username_channel\": {\n",
      "      \"terms\": {\n",
      "        \"script\": {\n",
      "          \"source\": \"\\n                        String username = doc.containsKey('username') && !doc['username'].empty ? doc['username'].value : 'unknown';\\n                        String channel = doc.containsKey('channel') && !doc['channel'].empty ? doc['channel'].value : 'unknown';\\n                        return username + '|' + channel;\\n                    \"\n",
      "        },\n",
      "        \"size\": 1000,\n",
      "        \"order\": [\n",
      "          {\n",
      "            \"user_influence_score_avg\": \"desc\"\n",
      "          },\n",
      "          {\n",
      "            \"followers_count\": \"desc\"\n",
      "          },\n",
      "          {\n",
      "            \"total_posts\": \"desc\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"aggs\": {\n",
      "        \"username\": {\n",
      "          \"terms\": {\n",
      "            \"field\": \"username\",\n",
      "            \"size\": 1\n",
      "          }\n",
      "        },\n",
      "        \"channel\": {\n",
      "          \"terms\": {\n",
      "            \"field\": \"channel\",\n",
      "            \"size\": 1\n",
      "          }\n",
      "        },\n",
      "        \"followers_count\": {\n",
      "          \"max\": {\n",
      "            \"script\": {\n",
      "              \"source\": \"\\n                                // Logic untuk followers dengan fallback - menggunakan max untuk mendapatkan nilai tertinggi per user\\n                                if (doc.containsKey('user_followers') && !doc['user_followers'].empty) {\\n                                    return doc['user_followers'].value;\\n                                } else if (doc.containsKey('user_connections') && !doc['user_connections'].empty) {\\n                                    return doc['user_connections'].value;\\n                                } else if (doc.containsKey('subscriber') && !doc['subscriber'].empty) {\\n                                    return doc['subscriber'].value;\\n                                } else {\\n                                    return 0;\\n                                }\\n                            \"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"total_posts\": {\n",
      "          \"value_count\": {\n",
      "            \"field\": \"username\"\n",
      "          }\n",
      "        },\n",
      "        \"viral_score_sum\": {\n",
      "          \"sum\": {\n",
      "            \"field\": \"viral_score\"\n",
      "          }\n",
      "        },\n",
      "        \"reach_score_sum\": {\n",
      "          \"sum\": {\n",
      "            \"field\": \"reach_score\"\n",
      "          }\n",
      "        },\n",
      "        \"unique_user_image_url\": {\n",
      "          \"terms\": {\n",
      "            \"field\": \"user_image_url\",\n",
      "            \"size\": 1\n",
      "          }\n",
      "        },\n",
      "        \"engagement_rate_sum\": {\n",
      "          \"sum\": {\n",
      "            \"field\": \"engagement_rate\"\n",
      "          }\n",
      "        },\n",
      "        \"unique_user_category\": {\n",
      "          \"terms\": {\n",
      "            \"field\": \"user_category.keyword\",\n",
      "            \"size\": 1\n",
      "          }\n",
      "        },\n",
      "        \"user_influence_score_avg\": {\n",
      "          \"avg\": {\n",
      "            \"script\": {\n",
      "              \"lang\": \"painless\",\n",
      "              \"params\": {\n",
      "                \"whitelist\": [\n",
      "                  \"kompas.com\",\n",
      "                  \"detik.com\",\n",
      "                  \"cnnindonesia.com\",\n",
      "                  \"cnbcindonesia.com\",\n",
      "                  \"suara.com\",\n",
      "                  \"tribunnews.com\",\n",
      "                  \"liputan6.com\",\n",
      "                  \"katadata.co.id\",\n",
      "                  \"apnews.com\",\n",
      "                  \"dawn.com\",\n",
      "                  \"republika.co.id\",\n",
      "                  \"viva.co.id\",\n",
      "                  \"idntimes.com\",\n",
      "                  \"mediaindonesia.com\",\n",
      "                  \"okezone.com\",\n",
      "                  \"tvonenews.com\",\n",
      "                  \"jpnn.com\",\n",
      "                  \"antaranews.com\",\n",
      "                  \"viva.co.id\"\n",
      "                ],\n",
      "                \"max_val\": 500.0\n",
      "              },\n",
      "              \"source\": \"\\n        double logNorm(def val, double max) {\\n            return Math.log(1 + val) / Math.log(1 + max);\\n        }\\n\\n        String channel = doc.containsKey('channel') && !doc['channel'].empty ? doc['channel'].value : \\\"\\\";\\n        double likes = doc.containsKey('likes') && !doc['likes'].empty ? doc['likes'].value : 0;\\n        double comments = doc.containsKey('comments') && !doc['comments'].empty ? doc['comments'].value : 0;\\n        double replies = doc.containsKey('replies') && !doc['replies'].empty ? doc['replies'].value : 0;\\n        double retweets = doc.containsKey('retweets') && !doc['retweets'].empty ? doc['retweets'].value : 0;\\n        double reposts = doc.containsKey('reposts') && !doc['reposts'].empty ? doc['reposts'].value : 0;\\n        double shares = doc.containsKey('shares') && !doc['shares'].empty ? doc['shares'].value : 0;\\n        double favorites = doc.containsKey('favorites') && !doc['favorites'].empty ? doc['favorites'].value : 0;\\n        double votes = doc.containsKey('votes') && !doc['votes'].empty ? doc['votes'].value : 0;\\n        double views = doc.containsKey('views') && !doc['views'].empty ? doc['views'].value : 0;\\n        double score = 0;\\n\\n        if (channel == 'twitter') {\\n            double E = logNorm(likes, params.max_val) * 0.4 + logNorm(replies, params.max_val) * 0.3 + logNorm(retweets, params.max_val) * 0.3;\\n            double R = logNorm(views, params.max_val);\\n            score = (0.7 * E + 0.3 * R) * 10;\\n        } else if (channel == 'linkedin') {\\n            double E = logNorm(likes, params.max_val) * 0.5 + logNorm(comments, params.max_val) * 0.3;\\n            double R = logNorm(reposts, params.max_val) * 0.2;\\n            score = (0.6 * E + 0.4 * R) * 10;\\n        } else if (channel == 'tiktok') {\\n            double E = logNorm(likes, params.max_val) * 0.4 + logNorm(comments, params.max_val) * 0.3 + logNorm(favorites, params.max_val) * 0.1;\\n            double R = logNorm(shares, params.max_val) * 0.2;\\n            score = (0.7 * E + 0.3 * R) * 10;\\n        } else if (channel == 'instagram') {\\n            if (views > 0) {\\n            double E = logNorm(likes, params.max_val) * 0.5 + logNorm(comments, params.max_val) * 0.3;\\n            double R = logNorm(views, params.max_val) * 0.2;\\n            score = (0.6 * E + 0.4 * R) * 10;\\n            } else {\\n            double E = logNorm(likes, params.max_val) * 0.6 + logNorm(comments, params.max_val) * 0.4;\\n            score = 0.6 * E * 10;\\n            }\\n        } else if (channel == 'reddit') {\\n            double E = logNorm(votes, params.max_val) * 0.6;\\n            double R = logNorm(comments, params.max_val) * 0.4;\\n            score = (0.6 * E + 0.4 * R) * 10;\\n        } else if (channel == 'youtube') {\\n            double E = logNorm(likes, params.max_val) * 0.4 + logNorm(comments, params.max_val) * 0.2;\\n            double R = logNorm(views, params.max_val) * 0.4;\\n            score = (0.6 * E + 0.4 * R) * 10;\\n        } else if (channel == 'news') {\\n            String username = doc.containsKey('username.keyword') && !doc['username.keyword'].empty ? doc['username.keyword'].value : \\\"\\\";\\n            double A = params.whitelist.contains(username) ? 1.0 : 0.0;\\n            double M = (doc.containsKey('post_media_link') && !doc['post_media_link'].empty && doc['post_media_link'].value.contains(\\\"http\\\")) ? 1.0 : 0.0;\\n            double Q = doc.containsKey('list_quotes.keyword') && !doc['list_quotes.keyword'].empty && doc['list_quotes.keyword'].value.contains(\\\"quotes\\\") ? 1.0 : 0.0;\\n            score = (0.8 * A + 0.1 * M + 0.1 * Q) * 10;\\n        }\\n\\n        return Math.min(score, 10.0);\\n    \"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"sentiment_positive\": {\n",
      "          \"filter\": {\n",
      "            \"term\": {\n",
      "              \"sentiment\": \"positive\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"sentiment_negative\": {\n",
      "          \"filter\": {\n",
      "            \"term\": {\n",
      "              \"sentiment\": \"negative\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"sentiment_neutral\": {\n",
      "          \"filter\": {\n",
      "            \"term\": {\n",
      "              \"sentiment\": \"neutral\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"unique_issues\": {\n",
      "          \"terms\": {\n",
      "            \"field\": \"issue.keyword\",\n",
      "            \"size\": 10\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:POST http://34.101.178.71:9200/linkedin_data/_search [status:200 duration:0.356s]\n",
      "INFO:elastic_transport.transport:POST http://34.101.178.71:9200/topic_cluster/_search [status:200 duration:0.067s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check topic map\n",
      "get map\n"
     ]
    }
   ],
   "source": [
    "hasil = search_kol(keywords = ['prabowo','gibran'],\n",
    "                   project_name='gibran raka',\n",
    "                   date_filter = 'lat year',\n",
    "                   owner_id = 5,channels = ['linkedin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb6c7045",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T18:24:31.121933Z",
     "start_time": "2025-05-24T18:24:31.096949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>channel</th>\n",
       "      <th>link_post</th>\n",
       "      <th>viral_score</th>\n",
       "      <th>reach_score</th>\n",
       "      <th>user_image_url</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>engagement_rate</th>\n",
       "      <th>user_category</th>\n",
       "      <th>user_influence_score</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>sentiment_negative</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>link_user</th>\n",
       "      <th>is_negative_driver</th>\n",
       "      <th>unified_issue</th>\n",
       "      <th>most_viral</th>\n",
       "      <th>share_of_voice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>mr-iqbal-masril-djanaik-78992122b</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>11</td>\n",
       "      <td>0.378460</td>\n",
       "      <td>4.054048</td>\n",
       "      <td>https://media.licdn.com/dms/image/v2/D4E03AQFd...</td>\n",
       "      <td>7814.0</td>\n",
       "      <td>626.014488</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.564584</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.linkedin.com/in/mr-iqbal-masril-dj...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Proposal for textile industry consolidation, ...</td>\n",
       "      <td>0.564584</td>\n",
       "      <td>8.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>erudite-risk</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>9</td>\n",
       "      <td>10.071918</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>https://media.licdn.com/dms/image/v2/C4D0BAQHC...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.193265</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.linkedin.com/in/erudite-risk</td>\n",
       "      <td>True</td>\n",
       "      <td>[Flood victim assistance and government respon...</td>\n",
       "      <td>0.193265</td>\n",
       "      <td>7.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>acrosticsasia</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>8</td>\n",
       "      <td>0.740449</td>\n",
       "      <td>0.551429</td>\n",
       "      <td>https://media.licdn.com/dms/image/v2/D560BAQHy...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.220211</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.linkedin.com/in/acrosticsasia</td>\n",
       "      <td>False</td>\n",
       "      <td>[Challenges facing Indonesia, Danantara's pote...</td>\n",
       "      <td>0.220211</td>\n",
       "      <td>6.349206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>indonesia-economic-summit-2025</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>https://media.licdn.com/dms/image/v2/D560BAQEd...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.linkedin.com/in/indonesia-economic...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Indonesia's efforts to attract private capita...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jimmy-saragi</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.565714</td>\n",
       "      <td>https://media.licdn.com/dms/image/v2/D5603AQFq...</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>216.666664</td>\n",
       "      <td>human</td>\n",
       "      <td>0.622719</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.linkedin.com/in/jimmy-saragi</td>\n",
       "      <td>True</td>\n",
       "      <td>[Inconsistency in Indonesian policy, Inconsist...</td>\n",
       "      <td>0.622719</td>\n",
       "      <td>2.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>netmedia101</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.linkedin.com/in/netmedia101</td>\n",
       "      <td>True</td>\n",
       "      <td>[Scams using Prabowo deepfakes]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>michaelwestmedia</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.linkedin.com/in/michaelwestmedia</td>\n",
       "      <td>True</td>\n",
       "      <td>[Indonesia's potential one-party state]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>marketinginteractive</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.linkedin.com/in/marketinginteractive</td>\n",
       "      <td>True</td>\n",
       "      <td>[Prabowo's economic policies and protests]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>kentaro-iwamoto</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.linkedin.com/in/kentaro-iwamoto</td>\n",
       "      <td>True</td>\n",
       "      <td>[Investor skepticism towards Danantara]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>wellington-capital-advisory</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>https://media.licdn.com/dms/image/v2/C560BAQHQ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.linkedin.com/in/wellington-capital...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Indonesia's economic growth target]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             username   channel  link_post  viral_score  \\\n",
       "58  mr-iqbal-masril-djanaik-78992122b  linkedin         11     0.378460   \n",
       "0                        erudite-risk  linkedin          9    10.071918   \n",
       "31                      acrosticsasia  linkedin          8     0.740449   \n",
       "66     indonesia-economic-summit-2025  linkedin          3     0.000000   \n",
       "1                        jimmy-saragi  linkedin          3     0.000000   \n",
       "..                                ...       ...        ...          ...   \n",
       "27                        netmedia101  linkedin          1     0.000000   \n",
       "26                   michaelwestmedia  linkedin          1     0.000000   \n",
       "25               marketinginteractive  linkedin          1     0.000000   \n",
       "24                    kentaro-iwamoto  linkedin          1     0.000000   \n",
       "90        wellington-capital-advisory  linkedin          1     0.000000   \n",
       "\n",
       "    reach_score                                     user_image_url  \\\n",
       "58     4.054048  https://media.licdn.com/dms/image/v2/D4E03AQFd...   \n",
       "0      0.057000  https://media.licdn.com/dms/image/v2/C4D0BAQHC...   \n",
       "31     0.551429  https://media.licdn.com/dms/image/v2/D560BAQHy...   \n",
       "66     0.000000  https://media.licdn.com/dms/image/v2/D560BAQEd...   \n",
       "1      0.565714  https://media.licdn.com/dms/image/v2/D5603AQFq...   \n",
       "..          ...                                                ...   \n",
       "27     0.000000                                                      \n",
       "26     0.000000                                                      \n",
       "25     0.000000                                                      \n",
       "24     0.000000                                                      \n",
       "90     0.000000  https://media.licdn.com/dms/image/v2/C560BAQHQ...   \n",
       "\n",
       "    user_followers  engagement_rate user_category  user_influence_score  \\\n",
       "58          7814.0       626.014488         Human              0.564584   \n",
       "0              0.0       100.000000         Human              0.193265   \n",
       "31             0.0       225.000000         Human              0.220211   \n",
       "66             0.0         0.000000         Human              0.000000   \n",
       "1           1141.0       216.666664         human              0.622719   \n",
       "..             ...              ...           ...                   ...   \n",
       "27             0.0         0.000000                            0.000000   \n",
       "26             0.0         0.000000                            0.000000   \n",
       "25             0.0         0.000000                            0.000000   \n",
       "24             0.0         0.000000                            0.000000   \n",
       "90             0.0         0.000000                            0.000000   \n",
       "\n",
       "    sentiment_positive  sentiment_negative  sentiment_neutral  \\\n",
       "58                  10                   0                  1   \n",
       "0                    3                   4                  2   \n",
       "31                   0                   1                  7   \n",
       "66                   2                   0                  1   \n",
       "1                    0                   3                  0   \n",
       "..                 ...                 ...                ...   \n",
       "27                   0                   1                  0   \n",
       "26                   0                   1                  0   \n",
       "25                   0                   1                  0   \n",
       "24                   0                   1                  0   \n",
       "90                   0                   0                  1   \n",
       "\n",
       "                                            link_user  is_negative_driver  \\\n",
       "58  https://www.linkedin.com/in/mr-iqbal-masril-dj...               False   \n",
       "0            https://www.linkedin.com/in/erudite-risk                True   \n",
       "31          https://www.linkedin.com/in/acrosticsasia               False   \n",
       "66  https://www.linkedin.com/in/indonesia-economic...               False   \n",
       "1            https://www.linkedin.com/in/jimmy-saragi                True   \n",
       "..                                                ...                 ...   \n",
       "27            https://www.linkedin.com/in/netmedia101                True   \n",
       "26       https://www.linkedin.com/in/michaelwestmedia                True   \n",
       "25   https://www.linkedin.com/in/marketinginteractive                True   \n",
       "24        https://www.linkedin.com/in/kentaro-iwamoto                True   \n",
       "90  https://www.linkedin.com/in/wellington-capital...               False   \n",
       "\n",
       "                                        unified_issue  most_viral  \\\n",
       "58  [Proposal for textile industry consolidation, ...    0.564584   \n",
       "0   [Flood victim assistance and government respon...    0.193265   \n",
       "31  [Challenges facing Indonesia, Danantara's pote...    0.220211   \n",
       "66  [Indonesia's efforts to attract private capita...    0.000000   \n",
       "1   [Inconsistency in Indonesian policy, Inconsist...    0.622719   \n",
       "..                                                ...         ...   \n",
       "27                    [Scams using Prabowo deepfakes]    0.000000   \n",
       "26            [Indonesia's potential one-party state]    0.000000   \n",
       "25         [Prabowo's economic policies and protests]    0.000000   \n",
       "24            [Investor skepticism towards Danantara]    0.000000   \n",
       "90               [Indonesia's economic growth target]    0.000000   \n",
       "\n",
       "    share_of_voice  \n",
       "58        8.730159  \n",
       "0         7.142857  \n",
       "31        6.349206  \n",
       "66        2.380952  \n",
       "1         2.380952  \n",
       "..             ...  \n",
       "27        0.793651  \n",
       "26        0.793651  \n",
       "25        0.793651  \n",
       "24        0.793651  \n",
       "90        0.793651  \n",
       "\n",
       "[91 rows x 18 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(hasil).sort_values(['share_of_voice'], ascending = False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
